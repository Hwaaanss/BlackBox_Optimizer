이전에 추론과정이 문제인지 결과파일 생성 시가 문제인지 해결했어야 했던 에러가 있었는데, 그 문제를 해결하고 recall 점수도 향상시켜서 제출 당시 0.8737864078 점으로 공동 2등을 달성했었다.
해결 방법은 for 문을 통해 sample_id 별로 TEST_000 부터 819까지 하나하나 추론을 해서 파일 생성하도록 했다. 피쳐 간의 상관관계를 고려해야 하나 고민을 했지만 일단 이 방법으로 성능과 문제를 해결했다.


# LSTM - ADAM - EarlyStopping - SolveProblem


import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import os

# 데이터 로드
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# ID 제거 및 타겟 변수 분리
train_data.drop(columns=['ID'], inplace=True)
target = train_data.pop('y')

# 데이터 스케일링
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(train_data)
y_scaled = scaler_y.fit_transform(target.values.reshape(-1, 1))

# LSTM 입력 형태로 변환
timesteps = 10
X_lstm = []
y_lstm = []

for i in range(len(X_scaled) - timesteps):
    X_lstm.append(X_scaled[i:i + timesteps])
    y_lstm.append(y_scaled[i + timesteps])

X_lstm = np.array(X_lstm)
y_lstm = np.array(y_lstm)

# 학습/검증 데이터 분리
X_train, X_val, y_train, y_val = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)

# 모델 생성 함수
def create_model(units=50, dropout_rate=0.2):
    model = Sequential()
    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(dropout_rate))
    model.add(LSTM(units))
    model.add(Dropout(dropout_rate))
    model.add(Dense(1))

    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# 모델 학습
model = create_model(units=100, dropout_rate=0.3)

model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=2)

# 모델 저장
os.makedirs('./model_saved/', exist_ok=True)
model.save('./model_saved/lstm_solved_model.h5')

# 테스트 데이터 예측 준비
test_ids = test_data['ID']
test_data.drop(columns=['ID'], inplace=True)

# 데이터 스케일링
test_data_scaled = scaler_X.transform(test_data)

# 예측 결과 저장을 위한 리스트 초기화
y_test_pred_list = []

# 각 테스트 데이터를 순차적으로 예측
for i in range(len(test_data_scaled) - timesteps + 1):
    X_test_sample = np.array([test_data_scaled[i:i + timesteps]])
    y_test_pred_scaled = model.predict(X_test_sample)
    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)
    y_test_pred_list.append(y_test_pred.flatten()[0])

# 마지막 9개의 예측 값 추가 (이전 예측에 포함되지 않은 마지막 시퀀스 예측)
for i in range(1, timesteps):
    X_test_sample = np.array([test_data_scaled[-(timesteps + i):]])
    y_test_pred_scaled = model.predict(X_test_sample)
    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)
    y_test_pred_list.append(y_test_pred.flatten()[0])

# 예측 결과를 DataFrame으로 변환
output = pd.DataFrame({'ID': test_ids, 'y': y_test_pred_list})

# 결과 저장
output.to_csv('submission.csv', index=False)

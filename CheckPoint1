train 데이터셋은 시계열 데이터이고, 모델기반 blackbox 최적화 알고리즘 개발이 목표이다.

# LSTM - ADAM - GridsearchCV - Private Recall : 0.8514851485


import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import os

# 데이터 로드
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# ID 제거 및 타겟 변수 분리
train_data.drop(columns=['ID'], inplace=True)
target = train_data.pop('y')

# 데이터 스케일링
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(train_data)
y_scaled = scaler_y.fit_transform(target.values.reshape(-1, 1))

# LSTM 입력 형태로 변환
timesteps = 10
X_lstm = []
y_lstm = []

for i in range(len(X_scaled) - timesteps):
    X_lstm.append(X_scaled[i:i+timesteps])
    y_lstm.append(y_scaled[i+timesteps])

X_lstm = np.array(X_lstm)
y_lstm = np.array(y_lstm)

# 학습/검증 데이터 분리
X_train, X_val, y_train, y_val = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)

# 모델 생성 함수
def create_model(units=50, dropout_rate=0.2):
    model = Sequential()
    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(dropout_rate))
    model.add(LSTM(units))
    model.add(Dropout(dropout_rate))
    model.add(Dense(1))
    
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# 모델 학습
model = create_model(units=100, dropout_rate=0.3)

model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), verbose=2)

# 모델 저장
os.makedirs('./model_saved/', exist_ok=True)
model.save('./model_saved/lstm_top_model.h5')

# 검증 데이터로 예측
predictions = model.predict(X_val)

# 스케일을 원래대로 복원
predictions_rescaled = scaler_y.inverse_transform(predictions)
y_val_rescaled = scaler_y.inverse_transform(y_val)

# 성능 평가 (상위 33%와 상위 25% 비교, Recall 계산)
predictions_sorted = np.argsort(predictions_rescaled.flatten())[::-1]
y_val_sorted = np.argsort(y_val_rescaled.flatten())[::-1]

top_33_percent_pred = predictions_sorted[:int(len(predictions_rescaled) * 0.33)]
top_25_percent_actual = y_val_sorted[:int(len(y_val_rescaled) * 0.25)]

common_elements = len(set(top_33_percent_pred).intersection(set(top_25_percent_actual)))
recall = common_elements / len(top_25_percent_actual)
print(f"Recall: {recall}")

# 테스트 데이터 예측
test_ids = test_data['ID']
test_data.drop(columns=['ID'], inplace=True)
test_data_scaled = scaler_X.transform(test_data)

# LSTM 입력 형태로 변환
X_test_lstm = []

for i in range(len(test_data_scaled) - timesteps):
    X_test_lstm.append(test_data_scaled[i:i+timesteps])

X_test_lstm = np.array(X_test_lstm)

# 예측 수행
y_test_pred_scaled = model.predict(X_test_lstm)
y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)

# 예측 결과를 원래 test.csv와 동일한 형태로 저장
output = pd.DataFrame({'ID': test_ids[timesteps:], 'y': y_test_pred.flatten()})
output.to_csv('submission.csv', index=False)


이렇게 했을 때 점수는 나쁘지 않게 나오나, submission.csv 파일에서 TEST_000~009 행이 사라지는 문제가 발생하므로 점수에서 손실이 분명히 존재한다. 반드시 해결해야 하는 문제이기도 하다.
